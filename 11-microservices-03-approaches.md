# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
  - В качестве облачной системы может подойти Yandex Cloud 
- Система контроля версий Git;
  - Для хранения кода могут подойти [GitLab](https://about.gitlab.com/), [BitBucket](https://bitbucket.org/product) и [GitHub](https://github.com/)
- Репозиторий на каждый сервис;
  - Во всех перечисленных системах можно хранить код отдельно для каждого сервиса  
- Запуск сборки по событию из системы контроля версий;
  - Сборку по событию из vcs поддерживают [Jenkins](https://www.jenkins.io/) и [TeamCity](https://www.jetbrains.com/teamcity/), но мы выберем последний из-за его возможности работать сразу с многими ветками репозитория 
- Запуск сборки по кнопке с указанием параметров;
  - В _TeamCity_ возможен запуск сбоки кода по нажатию кнопки, а не только по событию из vcs
- Возможность привязать настройки к каждой сборке;
  - Также _TeamCity_ обладает возможностью привязки настроек к каждой конкретной сборке
- Возможность создания шаблонов для различных конфигураций сборок;
  - Шаблоны билд конфигураций также можно использовать в _TeamCity_
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
  - Хранение секретов для _TeamCity_ можно организовать при помощи [HashiCorp Vault](https://www.vaultproject.io/) 
- Несколько конфигураций для сборки из одного репозитория;
  - Как было указано выше, _TeamCity_ имеет функционал для шаблонизации билд конфигураций. Это также применимо к одному конкретному репозиторию
- Кастомные шаги при сборке;
  - Кастомные шаги при сборке можно обеспечить подключением одному из шагов сборки собственного самописного скрипта.
- Собственные докер образы для сборки проектов;
  - Собственные докер-образы для сборки проектов можно хранить в локальном _image registry_ или на [Docker Hub](https://hub.docker.com/)
- Возможность развернуть агентов сборки на собственных серверах;
  - Билд агенты _TeamCity_ можно разворачивать на хостах Linux и Windows
- Возможность параллельного запуска нескольких сборок;
  - Функционал по запуску нескольких параллельных сборок также имеется в TeamCity
- Возможность параллельного запуска тестов;
  - Параллельное тестирование можно запускать на нескольких билд-агентах, что увеличит скорость такого тестирования

Обоснуйте свой выбор.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
  - В качестве хранилища в на данный исторических момент можно порекомендовать [_clickhouse_](https://clickhouse.com/)
- Минимальные требования к приложениям, сбор логов из stdout;
  - Сбор логов будем осуществлять при помощи [_vector_](https://vector.dev/docs/reference/configuration/sinks/clickhouse/), обладающим большим функционалом и хорошей документацией
- Гарантированная доставка логов до центрального хранилища;
  - сборщик логов _Vector_ [гарантирует](https://vector.dev/docs/about/under-the-hood/guarantees/) доставку до хранилища
- Обеспечение поиска и фильтрации по записям логов;
  - В качестве инструмента для поиска по записям логов можно применить [_redash_](https://redash.io/data-sources/clickhouse)
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
  - _Redash_ обладает [функционалом](https://redash.io/help/user-guide/users) для разграничения доступа к логам
- Возможность дать ссылку на сохраненный поиск по записям логов;
  - Возможно предоставления линков на поисковый запрос реализована в _Redash_ при помощи [параметров запросов](https://redash.io/help/user-guide/querying/query-parameters#parameter-settings)

Обоснуйте свой выбор.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
  - Сбор, хранение, анализ и аларминг можно реализовать при помощи стэка [node_exporter](https://github.com/prometheus/node_exporter), [Prometheus](https://prometheus.io/), [Grafana](https://grafana.com/), [Alermanager](https://github.com/prometheus/alertmanager)
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
  - Сбор метрик состояния ресурсов, потребляемых ресурсов и метрик сервисов будут осуществляться при помощи _node_exporter_ и _Prom_QL_ запросов 
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
  - В качестве пользовательского интерфейса в нашем варианте реализации системы мониторинга выступает _Grafana_
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;
  - Возможность настройки пользовательсих дашбордов [реализована](https://grafana.com/docs/grafana/latest/administration/plugin-management/#install-a-plugin) при помощи [плагинов](https://grafana.com/orgs/grafana/plugins)

Обоснуйте свой выбор.
  * Также можно применить стэк [TICK](https://www.influxdata.com/time-series-platform/) (Telegraf, InfluxDB, Chronograf, Kapacitor) являющимся современным и хорошо документированным решением

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
